# ğŸš€ **Auto Video Annotation System**

## ğŸ“œ **Table of Contents**
1. [ğŸ“Œ Introduction](#introduction)
2. [ğŸ¥ Video Processing Features](#video-processing-features)
3. [ğŸ› ï¸ Tech Stack](#tech-stack)
4. [âš™ï¸ Installation](#installation)
5. [ğŸš€ Usage](#usage)
6. [ğŸ”— API Endpoints](#api-endpoints)
7. [ğŸ“‚ Project Structure](#project-structure)
8. [ğŸ¤ Contributing](#contributing)
9. [ğŸ“œ License](#license)
10. [ğŸ™ Acknowledgments](#acknowledgments)

---

## ğŸ“Œ **1. Introduction**

### â“ **Problem Statement**  
â³ Manual video annotation is a slow, labor-intensive, and costly process, often leading to inconsistencies. Traditional methods struggle to scale efficiently, making it difficult to generate high-quality, large-scale annotated datasets across different domains.

### ğŸ’¡ **Solution**  
This **Auto Video Annotation System** leverages state-of-the-art AI models to automate video labeling, improving efficiency and scalability while maintaining accuracy.

### ğŸ”¥ **Key Features**  
âœ… **Automated Annotation Pipeline** â€“ Uses advanced AI model *Grounding DINO* to detect and label objects in videos, reducing manual effort.  
âœ… **Scalable & Efficient System** â€“ Built with a lightweight, high-performance FastAPI backend for seamless integration and large-scale data processing.  
âœ… **Optimized Video Processing** â€“ Implements frame segmentation (*SAM*) and propagation (*SAMv2*) to minimize redundant computation while maintaining accuracy.  
âœ… **Reliable Info Monitoring** â€“ Includes *Supervision* for annotation handling, and robust logging for debugging and consistency.  

This system is designed to streamline video annotation workflows, making large-scale dataset preparation faster and more efficient. ğŸš€

---

## ğŸ¥ **2. Video Processing Features**

ğŸ¯ **Zero-shot detection â†’ labeling â†’ segmentation**  
ğŸï¸ **Customizable FPS** â€“ Users can adjust the frames per second (FPS) to optimize processing time.  
â¸ï¸ **Interrupts for annotation refinement**:  
  ğŸ”¹ **STOPPROCESS** â€“ Users can stop the segmentation at any point and retrieve the segmented video up to that point.  
  ğŸ”¹ **STOPDETECTION** â€“ Users can halt new object detection while continuing segmentation of previously detected objects across the video.  
  ğŸ”¹ **Refinement Interrupt** â€“ Users can refine tight segmentation masks by adding positive/negative click labels for specific objects.  

---

## ğŸ› ï¸ **3. Tech Stack**

| ğŸ–¥ï¸ Technology | ğŸ” Purpose |
|------------|---------|
| ğŸ **Python** | Primary development language |
| âš¡ **FastAPI** | API framework for seamless integration |
| ğŸ“Š **Supervision** | Utility for managing and visualizing annotations |
| ğŸ”„ **Threading** | Enables parallel video processing in the background |
| ğŸ“œ **Logging** | Capturing runtime events for debugging and monitoring |
| ğŸ¥ **OpenCV (cv2)** | Handles video processing and frame extraction |
| ğŸ§© **SAM (Segment Anything Model)** | Automatic object segmentation |
| ğŸï¸ **SAMv2** | Video propagation functionality |
| ğŸ¯ **Grounding DINO** | Zero-shot object detection and labeling |

---

## âš™ï¸ **4. Installation**

Follow these steps to set up the project:

```sh
# ğŸ“¥ Clone the repository
git clone https://git.acldigital.com/ai-ml/autolabelling.git
```

```sh
# ğŸ“‚ Navigate to the project directory
cd Auto_labelling/
```

```sh
# âš™ï¸ Run the setup script
bash setup.sh
```

---

## ğŸš€ **5. Usage**

### â–¶ï¸ **Run the application**
```sh
python App.py
```

### ğŸ“œ **API Calls**  
ğŸ“„ Check the `api_call.txt` file for example API request commands.

---

## ğŸ”— **6. API Endpoints**

| ğŸ“¡ Method | ğŸ”— Endpoint | ğŸ“‹ Description |
|--------|---------|-------------|
| `ğŸ“¤ POST` | `/upload` | Uploads a video for processing |
| `ğŸ“¥ GET` | `/status/{job_id}` | Retrieves the processing status of a video |
| `ğŸ›‘ POST` | `/stopprocess` | Stops video segmentation at the current frame |
| `ğŸ›‘ POST` | `/stopdetection` | Stops new object detection but continues segmentation |
| `âœï¸ POST` | `/refine` | Allows the user to refine segmentation masks |

---

## ğŸ“‚ **7. Project Structure**

```
/project-root
â”œâ”€â”€ src/                # ğŸš€ Source code
â”œâ”€â”€ data/               # ğŸ“‚ Dataset (if any)
â”œâ”€â”€ models/             # ğŸ¤– ML models (if applicable)
â”œâ”€â”€ notebooks/          # ğŸ“’ Jupyter notebooks (if applicable)
â”œâ”€â”€ docs/               # ğŸ“‘ Documentation
â”œâ”€â”€ tests/              # âœ… Unit tests
â”œâ”€â”€ requirements.txt    # ğŸ“œ Dependencies
â”œâ”€â”€ README.md           # ğŸ“ Project README
```

---

## ğŸ¤ **8. Contributing**

We welcome contributions! ğŸ‰ To contribute:

```sh
# ğŸ´ Fork the repository
git fork https://git.acldigital.com/ai-ml/autolabelling.git
```

```sh
# ğŸŒ¿ Create a new branch
git checkout -b feature-xyz
```

```sh
# ğŸ’¾ Make your changes and commit them
git commit -m "Added new feature"
```

```sh
# ğŸ”€ Push your branch and open a Pull Request
git push origin feature-xyz
```

For detailed contribution guidelines, refer to `CONTRIBUTING.md`. ğŸ› ï¸

---

## ğŸ“œ **9. License**

ğŸ“ This project is licensed under the MIT License. See the `LICENSE` file for details.

---

## ğŸ™ **10. Acknowledgments**

A huge thanks to:
- ğŸ™Œ The developers and contributors of **Grounding DINO, SAM, and FastAPI**.
- ğŸ’¡ Open-source AI research communities for pushing the boundaries of video annotation.
- ğŸ¢ **[Your Team/Company Name]** for providing resources and support.

---

This **Auto Video Annotation System** is built for efficiency and scalability. Happy annotating! ğŸ¥ğŸš€

